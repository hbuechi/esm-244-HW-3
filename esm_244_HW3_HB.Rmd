---
title: "ESM 244 Homework 3"
author: "Hanna Buechi"
date: "3/3/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages_data, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

library(tidyverse)
library(tseries)
library(forecast)
library(plm)
library(Ecdat)
library(lmtest)
library(car)
library(effsize)
library(pwr)
library(plyr)
library(sf)
library(tmap)
library(leaflet)
library(ggrepel)
library(ggspatial)
library(RColorBrewer)
library(raster)
library(ggrepel)

truckee <- read_csv("truckee_flow.csv")
lizard <- read_csv("lter_lizard_pitfall.csv")

## Truckee River data

# mean_va -> mean monthly discharge in cubic feet per second
# year and month are self-explanatory

## Lizard data

# Zone: vegetation zone (C=creosote bush, G=grassland, M=mesquite, P=playa, T=tarbush)
# Site: Site location (CALI GRAV SAND; BASN IBPE SUMM; RABB NORT WELL; COLL SMAL TOBO; EAST TAYL WEST)
# Plot: Plot A, B, C, D
# Pit: Pit number (1 -16)
# Spp: Species code (CNTI, UTST, CNTE, CNIN, SCUN, HOMA, EUOB) # check more of these
# Sex: M (male), F (female), J (juvenile)
# Rcap: Recaptured  (N=new capture, R = recapture)
# Toenum: Toe mark number (includes Tail Mark beginning 3/16/95)
# SV-L: Snout-vent length in mm
# Total-length: Total length in mm
# Weight: Body weight in grams
# Tail: Tail condition (B = broken, W = whole)
# PC: Problem code (1 = see history log; 0 = no problem)

```

###Task 2: 

####Part a: Decomposed time series graphs
```{r time_graphs, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

# I did some data clean up in Excel because it was quick and easy

# create a vector of time series-specific data # the original df doesn't work with tseries()

mean_ts <- ts(truckee$mean_va, frequency = 12, start = c(2000,1)) # frequency = 12 indicates that this is monthly data that starts in 2000

# mean_ts # look at it to confirm that everything worked - yes, it ends in September 2016

# plot(mean_ts) # plot to explore the trend, seasonality, cycle

# a little bit of a downward trend
# seasonality: the annual, intermediate peaks
# cyclical: the big peaks are repeated twice

mean_dc <- decompose(mean_ts) # does Steps 1-4 of decomposition (Detect trend, de-trend by subtraction, calculate average seasonal component (ASC), "random/remainder" is cycle)

plot(mean_dc) # original, trend, seasonality, residuals that show trends that don't depend on the other decompositions

# flat lines for seasonality and cycle would indicate no contribution to time series variation/pattern
# I'm interested in those peaks in 2006/2007 and 2012 - where does the variation come from?
# They are still seen in trend, not seen in seasonality, still seen in cycle -> attribute to cycle
# seasonality is strong (scale is 1/6 of scale of observed) and very regular
# cycle peaks/troughs are very similar to observed data

```

The monthly mean discharge of the Truckee River is additive (the peaks have roughly the same frequency and amplitude) and there is an overall downward trend between 2000 and 201. There are also strong seasonal (by year) and cyclical components; I'm comparing the scales of each graph to make that claim. The cyclical decomposition shows a lot of variability in ~2006/2007 and ~2012, both of which were wet periods in two decades characterized by drought. (Reference: https://www.drought.gov/drought/states/california)

####Part b: Holt-Winters or ARIMA for forecasting
```{r about_the_tests, warning=FALSE, message=FALSE, errors=FALSE, include = FALSE, results='hide'}

#Holt-Winters: triple exponential smoothing (alpha, beta, gamma), uses smoothing factors to weight more recent time points more in prediction, based on trend and seasonality

# Autoregressive Integrated Moving Average (ARIMA): needs at least 40 historic observations, all time points are weighted equally, works with or without seasonality

# There is seasonality in the Truckee River time series data, so either should work.

```

```{r ACF, warning=FALSE, message=FALSE, errors=FALSE, include = FALSE, results='hide'}

# two ways to visualize ACF

# mean_acf <- acf(mean_ts) # acf = autocorrelation function
# mean_ggacf <- ggtsdisplay(mean_ts) # displays original data and ACF, which is nice

# peaks every 12 months; those peaks and two months on eiter side are correlated to x-sub-0, as are the two months directly after x-sub-0; there are troughs every 6 months, those are also correlated to x-sub-0, the trough 28 months away is the most correlated of the troughs

```

Holt-Winters exponential smoothing coefficients:
```{r holt_winters, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

mean_hw <- HoltWinters(mean_ts)

# alpha = 0.2418713, beta = 0, gamma = 0.3384547
# coefficients will be used in linear combinations for forecasting

# mean_plot <- plot(mean_hw) # looks pretty good with original data

```

Holt-Winters forecasting, 5 years into the future:
```{r HW_forecasting, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

mean_forecast <- forecast(mean_hw, h = 60) # 60 months = 5 years into the future - remember, we defined this as monthly data using the tserie() package
# forecast_plot <- plot(mean_forecast)

# SEASONALITY is dominating, we don't get much input from the past cyclical peaks, probably because HW weight recent observations

# dark grey ribbons 80% CI, light grey 95% CI

```

####Part c: Check Holt-Winters residuals:
```{r HW_residuals, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

par(mfrow = c(1,2))
hist(mean_forecast$residuals)
qqnorm(mean_forecast$residuals)

# Residuals look normally distributed

```

####Extra: ARIMA for comparison
```{r ARIMA, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

mean_pdq <- auto.arima(mean_ts)
mean_pdq

# p,d,q non-seasonal: (2,1,1); seasonal (0,0,2)

# fit the model

mean_arima <- arima(mean_ts, order = c(2,1,1), seasonal = list(order = c(0,0,2)))
mean_arima

# Check out the residuals: they look normally distributed

# par(mfrow = c(1,2))
# hist(mean_arima$residuals)
# qqnorm(mean_arima$residuals)
```

```{r ARIMA_forecast, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

# forecast

forecast_mean <- forecast(mean_arima, h = 60) # 60 time periods / months = 5 years
plot(forecast_mean)

# This doesn't look good...

```

###Task 3: Mapping California's National Parks
```{r wrangle_spatial_data, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

# Remember: .shp - geometries, .dbf - attributes, .prj - projections --> if there is no projection associated, we'll have to set one

ca_counties <- read_sf(".", layer = "california_county_shape_file") # "." indicates current working directory
st_crs(ca_counties) = 4326 # transform projection system to WGS84
parks <- read_sf(".", layer = "nps_boundary" ) # I imagine I'll have to clip this to California
st_crs(parks) = 4326 # st_crs(parks) to confirm

# Clip National Parks data by California Counties data
parks_clip <- st_intersection(parks, ca_counties) %>%
  filter(UNIT_TYPE == "National Park") %>% 
  dplyr::rename(Park = UNIT_NAME)

parks_clip <- parks_clip %>% 
  mutate(PARKNAME = ifelse(is.na(parks_clip$PARKNAME), "Redwood", parks_clip$PARKNAME))

```

```{r map, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

# counties to be background, parks to be foreground: code for ecoregions (analogous to parks_clip) and dams from Lab 6 will be helpful

parks_coords <- parks_clip %>% 
  st_centroid %>% # find polygon centroids (sf points object)
  st_coordinates # extract the coordinates of these points as a matrix

# insert centroid long and lat fields as attributes of polygons
parks_clip$long <- parks_coords[,1] # base R syntax for first column, which is X aka. longitude
parks_clip$lat <- parks_coords[,2]

# separate df for labeling, only the one entry for each park - do this manually, unfortunately
# Matt gave me an easier way: DON'T clip the nps_boundary to ca_counties because that makes the separate park/county polygons. Instead, keep them separate and filter nps_boundary by state (California) and map as a separate layer. Thanks, Matt! Example code saved in Github.

parks_label <- parks_clip %>% 
  slice(c(2,3,8,11,17,14,15,22,23))

ggplot(parks_clip) +
  geom_sf(data = ca_counties, # add the county borders
          fill = "papayawhip",
          color = "gray 30",
          size = 0.05)+
  geom_sf(fill = "springgreen4",
          color = "NA", # no borders around the polygons
          show.legend = FALSE) + # gets rid of legend
  ggtitle("California's National Parks") +
  coord_sf(datum = NA) +
  geom_label_repel(data=parks_label,
                  aes(long, lat, label = PARKNAME), 
                  alpha = 0.75, size = 2, 
                  fontface = "bold",
                  min.segment.length = unit(0, 'lines'),
                  nudge_x = 0.5, 
                  nudge_y = 0.5) +
  labs(x = " ", y = " ") +
  theme_minimal()


```




###Task 4: Lizards in the Northern Chihuahan Desert - Data Wrangling and Analysis
```{r panel_regression_INCORRECT, eval=FALSE}

weight <- lizard %>% 
  filter(site == "CALI") %>% 
  filter(sex == "M" | sex == "F") %>% 
  filter(weight > 0) %>%
  filter(toe_num > 0)

tail <- lizard %>%
  filter(site == "CALI") %>% 
  filter(sex == "M" | sex == "F") %>% 
  filter(tail == "B" | tail == "W")

# panel regression because some individuals are sampled multiple times - I know this based on toe number
# however, this is not a balanced panel

# other variables that might explain weight: total_length, SV_length, tail

# data is our time variable

# What is the effect of sex on lizard weight?

weight_panel <- weight %>% 
  select(date, sex, total_length, SV_length, tail, weight, toe_num)

weight_panel$date <- as.Date(weight_panel$date, "%m/%d/%y")
weight_panel$sex <- as.factor(weight_panel$sex)
weight_panel$total_length <- as.numeric(weight_panel$total_length)
weight_panel$SV_length <- as.numeric(weight_panel$SV_length)
weight_panel$toe_num <- as.numeric(weight_panel$toe_num)
weight_panel$tail <- as.factor(weight_panel$tail)

# kept getting an error that there was a duplicate entry for date and toe number - it's toe number 4 - this could have been a data entry mistake, I think that one of those duplicates should have been a male lizard - interesting that toe-number can be repeated between Male and Female!

# Index by sex too: now error because also toe_number 1: same date, same sex, same toe_number

weight_panel <- weight_panel %>% 
  filter(toe_num != 4) %>% 
  filter(toe_num != 1)

# weight_model <- plm(weight ~ sex + total_length + tail,
                  #data = weight_panel,
                  #index = c("date","toe_num", "sex"),
                  #model = "within") # entity fixed effects model

# this still isn't working, time to move on

```

####Part 1. For all lizards trapped at site ‘CALI’, do weights of male and female adult lizards differ significantly?

#####Mann-Whitney U Test (distributions aren't normal)
```{r ttest, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

# Lab 4 from ESM 206 for reference

## Data wrangling: separate df for sexes, make sure there aren't "." for weight, filter out recaptured animals so that they aren't counted twice (I'm hoping that toe_num isn't a unique identifier and that the dates are relevant...)
male <- lizard %>%
  filter(site == "CALI" | sex == "M") %>%
  filter(weight > 0) %>% 
  dplyr::select(weight, rcap, tail) %>% 
  filter(rcap != "R")

female <- lizard %>% 
  filter(site == "CALI", sex == "F") %>%
  filter(weight > 0) %>% 
  dplyr::select(weight, rcap, tail) %>% 
  filter(rcap != "R")

male$weight <- as.numeric(male$weight)
female$weight <- as.numeric(female$weight)

## Vector of weights
m <- male$weight
f <- female$weight

## Check sample sizes: they are very different!!
length(m) # 840
length(f) # 61

## Check for normality: neither histograms indicate normality (makes sense, can't have weights below 0) and Q-Q plots don't follow a 45-deg line --> non-parametric test
# par(mfrow = c(2, 2)) # two columns, two rows
# hist(m)
# qqnorm(m)
# hist(f)
# qqnorm(f)

## Test for equal variances: Null hypothesis is that variances are equal --> yes, p = 0.28
f_test <- var.test(m, f)
f_test

MWU <- wilcox.test(m,f)
MWU

## Parametric t-test: same conclustion to non-parametric test
# t_test_diff <- t.test(m, f, var.equal = TRUE)
# t_test_diff

```

There is no significant difference in mean weight for male (n=840) and female (n=61) lizards captured at the "CALI" site between 1989 and 2006 (f(839) = 0.83, p = 0.28, alpha = 0.05).

####Part 2. For lizards trapped at the ‘CALI’ site, is there a significant difference in the proportion of adult male and female lizards with broken tails?

#####Chi-square test
```{r contingency_table, warning=FALSE, message=FALSE, errors=FALSE, results='hide'}

# Lab 6 from ESM 206 for reference

male_tail <- male %>%
  dplyr::select(tail) %>%
  filter(tail == "B" | tail == "W")

female_tail <- female %>%
  dplyr::select(tail) %>%
  filter(tail == "B" | tail == "W")

# How many of each sex have whole or broken tails?

as.data.frame(table(female_tail$tail)) # 48, 13
as.data.frame(table(male_tail$tail)) # 638, 198

# Make a contingency table

ff <- c(48,13)
mm <- c(638,198)

tail_status <- rbind(ff, mm)
colnames(tail_status) <- c("Whole", "Broken")

tail_prop_table <- prop.table(tail_status, margin = 1) # calculate probabilities by row

# Null hypothesis: proportions of broken vs. whole tail are the same within each sex

tail_chi <- chisq.test(tail_status)
tail_chi

```

There is no significant difference in the proportion of males and females with broken tails  that were captured at the "CALI" sampling site ($\chi$^2(1) = 0.070, p = 0.79, $\alpha$ = 0.05). For both sexes, about 75% had whole, unbroken tails.
